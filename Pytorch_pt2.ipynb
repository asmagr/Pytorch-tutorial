{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec53949",
   "metadata": {},
   "source": [
    "In this notebook, I learned how to calculate gradients using the autograd package in PyTorch : the meaning behind required_grad paramter, what a computational graph is, how to stop autograd from tracking history and finally how to empty (zero) gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6a7ce",
   "metadata": {},
   "source": [
    "## Part 2 : Gradient Calculation With Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5628c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25068b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2495, 0.1581, 0.9390], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x= torch.rand(3, requires_grad= True) #This is necessary when we want to calculate the gradient of a tensor.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae193be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2495, 2.1581, 2.9390], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y= x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3ac18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.1206,  9.3150, 17.2754], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z= y*y*2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbf3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.2370, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z= z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da3151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9994, 2.8775, 3.9187])\n"
     ]
    }
   ],
   "source": [
    "z.backward() #dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cbbc3",
   "metadata": {},
   "source": [
    "The attribute .grad() is None by default and becomes a Tensor the first time a call to backward() computes gradients for self. The attribute will then contain the gradients computed and future calls to backward() will accumulate (add) gradients into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ac5a3",
   "metadata": {},
   "source": [
    "Now, this is how to stop pytorch from tracking the history in our computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa986b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2495, 0.1581, 0.9390])\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(False)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4adc72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2495, 0.1581, 0.9390])\n"
     ]
    }
   ],
   "source": [
    "y= x.detach()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcfc9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2495, 2.1581, 2.9390])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y= x+2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01229cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights= torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range (3):\n",
    "    \n",
    "    model_output= (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
